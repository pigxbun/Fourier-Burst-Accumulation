{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from SuperGlue import *\n",
    "p = 11\n",
    "ks = 50\n",
    "Use_SIFT = False\n",
    "# Use the clearest image as the reference image for burst registration\n",
    "select_ref_img = True\n",
    "burst_path = '../images/bookshelf'\n",
    "file_extension = '*.jpg'\n",
    "gaussian_ksize = 31  # gaussian kernel size\n",
    "burst = read_burst(burst_path, file_extension)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bursr Registration\n",
    "reference source: `https://learnopencv.com/image-alignment-feature-based-using-opencv-c-python/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if select_ref_img:\n",
    "    change_reference(burst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "process:1/10\n",
      "process:2/10\n",
      "process:3/10\n",
      "process:4/10\n",
      "process:5/10\n",
      "process:6/10\n",
      "process:7/10\n",
      "process:8/10\n",
      "process:9/10\n"
     ]
    }
   ],
   "source": [
    "if Use_SIFT:\n",
    "    burst = register_burst(burst)\n",
    "else:\n",
    "    burst = register_burst_SuperGlue(burst, copy=False, force_cpu=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the edge in order to remove black pixels\n",
    "burst = burst[:, 20:-20, 20:-20, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2161, 3461, 3)\n"
     ]
    }
   ],
   "source": [
    "# visualize warp result\n",
    "print(burst.shape)\n",
    "plt.figure(figsize=(100, 80))\n",
    "for i in range(burst.shape[0]):\n",
    "    plt.subplot(math.ceil(burst.shape[0]/3), 3, i+1)\n",
    "    plt.imshow(cv2.cvtColor(burst[i], cv2. COLOR_BGR2RGB))\n",
    "plt.savefig('./warp_result.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of pixels less than 0: 0\n",
      "# of pixels more than 255: 357794\n"
     ]
    }
   ],
   "source": [
    "# np.moveaxis: change the shape from (# of img, R, C, color) to (# of img, color, R, C)\n",
    "spectrums = np.fft.fft2(np.moveaxis(burst, 3, 1))\n",
    "# spectrum.shape = (# of img, color, R, C)\n",
    "\n",
    "# get the spectrum of a blur kernel\n",
    "shape = spectrums.shape[-2:]\n",
    "sig = min(shape)/ks\n",
    "# blur_kernel_spectrum=get_gau_ker(gaussian_ksize, sig, shape)[1]\n",
    "\n",
    "# average color channels\n",
    "weight = np.mean(np.abs(spectrums), axis=1)\n",
    "\n",
    "# pass through the gaussian filter\n",
    "weight = np.fft.fftshift(weight)\n",
    "for i in range(weight.shape[0]):\n",
    "    weight[i] = cv2.GaussianBlur(weight[i, :, :], (31, 31), sig)\n",
    "weight = np.fft.ifftshift(weight)\n",
    "\n",
    "weight = np.power(weight, p)\n",
    "weight /= np.sum(weight, axis=0)\n",
    "\n",
    "# expand the shape of the weight from (# of img, R, C) to (# of img, color, R, C)\n",
    "weight = np.repeat(np.expand_dims(weight, axis=1), 3, axis=1)\n",
    "\n",
    "# restore image\n",
    "spectrum_restored = np.sum(weight*spectrums, axis=0)\n",
    "image_restored = np.fft.ifft2(spectrum_restored)\n",
    "\n",
    "# change the shape from (color, R, C) to (R, C, color)\n",
    "image_restored = np.moveaxis(image_restored, 0, 2)\n",
    "\n",
    "# restore to uint8\n",
    "image_restored = image_restored.real\n",
    "print(\n",
    "    f'# of pixels less than 0: {np.sum(image_restored<0)}\\n# of pixels more than 255: {np.sum(image_restored>255)}')\n",
    "image_restored = np.where(image_restored < 0, 0, image_restored)\n",
    "image_restored = np.where(image_restored > 255, 255,\n",
    "                          image_restored).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "The weight of the first image is the largest in high frequency\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100, 80))\n",
    "for i in range(burst.shape[0]):\n",
    "    plt.subplot(math.ceil(burst.shape[0]/3), 3, i+1)\n",
    "    plt.imshow(np.fft.fftshift(weight[i, 0]), 'magma')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(visible=False)\n",
    "    plt.yticks(visible=False)\n",
    "plt.savefig('./weight.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attempt to do some post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# do unsharp masking in spatial domain\n",
    "img_unsharp_masking = unsharp_masking(image_restored, 5/6)\n",
    "cv2.imwrite('result_post_unsharp_masking.png', img_unsharp_masking)\n",
    "\n",
    "# do non-local means\n",
    "img_non_local_means = cv2.fastNlMeansDenoisingColored(\n",
    "    image_restored, None, 5, 5, 7, 21)\n",
    "cv2.imwrite('result_post_non_local_denoising.png', img_non_local_means)\n",
    "\n",
    "# higt-pass filter with different filter\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5, -1],\n",
    "                   [0, -1, 0]])\n",
    "img_high_pass = cv2.filter2D(image_restored, -1, kernel)\n",
    "cv2.imwrite('result_post_high_pass.png', img_high_pass)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input: img_restored\n",
    "# output: img_restored\n",
    "\n",
    "# post processing (image sharpening)\n",
    "# image_sharpen = gaussian_sharpen(image_restored, 500, 0.7)\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1, 9, -1],\n",
    "                   [-1, -1, -1]])\n",
    "image_sharpen = cv2.filter2D(src=image_restored, ddepth=-1, kernel=kernel)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result.png', image_restored)\n",
    "cv2.imwrite('result_sharpen.png', image_sharpen)\n",
    "# plt.figure(figsize=(100,80))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.title('result', fontsize=60)\n",
    "plt.xticks(visible=False)\n",
    "plt.yticks(visible=False)\n",
    "plt.imshow(cv2.cvtColor(image_restored, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.xticks(visible=False)\n",
    "plt.yticks(visible=False)\n",
    "plt.title('sharpen result', fontsize=60)\n",
    "plt.imshow(cv2.cvtColor(image_sharpen, cv2.COLOR_BGR2RGB))\n",
    "plt.savefig('./result_comparison.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier spectrums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = [[cv2.imread(\n",
    "    os.path.join(burst_path, 'result/out_fba.jpg'), 0), 'Frequency Domain of Paper Results'],\n",
    "    [cv2.cvtColor(image_restored, cv2.COLOR_BGR2GRAY),\n",
    "     'Frequency Domain of Our Results'],\n",
    "    [cv2.cvtColor(image_sharpen, cv2.COLOR_BGR2GRAY), 'Frequency Domain of Our Sharpen Results']]\n",
    "plt.figure(figsize=(30, 10))\n",
    "for i in range(len(imgs)):\n",
    "    plt.subplot(1, 3, 1+i)\n",
    "    spectrum = np.fft.fftshift(np.fft.fft2(imgs[i][0]))\n",
    "    plt.imshow(np.log10(np.abs(spectrum)), 'magma')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(visible=False)\n",
    "    plt.yticks(visible=False)\n",
    "    plt.title(imgs[i][1])\n",
    "plt.savefig('./freq.png')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
