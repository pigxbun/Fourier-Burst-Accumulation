{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from SuperGlue import *\n",
    "p=11\n",
    "ks=50\n",
    "Use_SIFT=False\n",
    "burst_path = '../images/bookshelf'\n",
    "file_extension='*.jpg'\n",
    "gaussian_ksize=31 # gaussian kernel size\n",
    "burst=read_burst(burst_path, file_extension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bursr Registration\n",
    "reference source: `https://learnopencv.com/image-alignment-feature-based-using-opencv-c-python/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the clearest image as the reference image for burst registration\n",
    "a = np.fft.fft2(np.moveaxis(burst, 3, 1))\n",
    "a = np.sum(np.abs(a), axis=(1, 2, 3))\n",
    "a = np.argmax(a)\n",
    "burst[[0, a], :, :, :] = burst[[a, 0], :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference on device \"cuda\"\n",
      "Loaded SuperPoint model\n",
      "Loaded SuperGlue model (\"indoor\" weights)\n",
      "process:1/10\n",
      "process:2/10\n",
      "process:3/10\n",
      "process:4/10\n",
      "process:5/10\n",
      "process:6/10\n",
      "process:7/10\n",
      "process:8/10\n",
      "process:9/10\n"
     ]
    }
   ],
   "source": [
    "if Use_SIFT:\n",
    "    burst=register_burst(burst)\n",
    "else:\n",
    "    burst=register_burst_SuperGlue(burst, copy=False, force_cpu=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut the edge in order to remove black pixels\n",
    "burst=burst[:,20:-20, 20:-20,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 2161, 3461, 3)\n"
     ]
    }
   ],
   "source": [
    "# visualize warp result\n",
    "print(burst.shape)\n",
    "plt.figure(figsize=(100,80))\n",
    "for i in range(burst.shape[0]):\n",
    "    plt.subplot(math.ceil(burst.shape[0]/3),3,i+1)\n",
    "    plt.imshow(cv2.cvtColor(burst[i],cv2. COLOR_BGR2RGB))\n",
    "\n",
    "if Use_SIFT:\n",
    "    plt.show()\n",
    "else:\n",
    "    plt.savefig('./warp_result.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FBA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of pixels less than 0: 0\n",
      "# of pixels more than 255: 357794\n"
     ]
    }
   ],
   "source": [
    "# np.moveaxis: change the shape from (# of img, R, C, color) to (# of img, color, R, C)\n",
    "spectrums=np.fft.fft2(np.moveaxis(burst, 3, 1))\n",
    "# spectrum.shape = (# of img, color, R, C)\n",
    "\n",
    "# get the spectrum of a blur kernel\n",
    "shape=spectrums.shape[-2:]\n",
    "sig=min(shape)/ks\n",
    "# blur_kernel_spectrum=get_gau_ker(gaussian_ksize, sig, shape)[1]\n",
    "\n",
    "# average color channels\n",
    "weight=np.mean(np.abs(spectrums), axis=1)\n",
    "\n",
    "# pass through the gaussian filter\n",
    "# weight=weight*blur_kernel_spectrum\n",
    "weight=np.fft.fftshift(weight)\n",
    "for i in range(weight.shape[0]):\n",
    "        weight[i]=cv2.GaussianBlur(weight[i,:,:], (31,31), sig)\n",
    "weight=np.fft.ifftshift(weight)\n",
    "\n",
    "weight=np.power(weight, p)\n",
    "weight/=np.sum(weight, axis=0)\n",
    "\n",
    "# expand the shape of the weight from (# of img, R, C) to (# of img, color, R, C)\n",
    "weight=np.repeat(np.expand_dims(weight, axis=1), 3, axis=1)\n",
    "\n",
    "# restore image\n",
    "spectrum_restored=np.sum(weight*spectrums, axis=0)\n",
    "image_restored=np.fft.ifft2(spectrum_restored)\n",
    "\n",
    "# change the shape from (color, R, C) to (R, C, color)\n",
    "image_restored=np.moveaxis(image_restored, 0, 2)\n",
    "\n",
    "# restore to uint8\n",
    "image_restored=image_restored.real\n",
    "print(f'# of pixels less than 0: {np.sum(image_restored<0)}\\n# of pixels more than 255: {np.sum(image_restored>255)}')\n",
    "image_restored=np.where(image_restored<0,0,image_restored)\n",
    "image_restored=np.where(image_restored>255,255,image_restored).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=np.fft.ifft2(spectrum_restored)\n",
    "b=np.moveaxis(t.real, 0, 2)\n",
    "b=b-b.min()\n",
    "b=(b/b.max()*255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "第一張圖的weight在邊緣會比較高\n",
    "所以是不是要盡力挑第一張圖，也就是別人對齊的參考圖?\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(100,80))\n",
    "for i in range(burst.shape[0]):\n",
    "    plt.subplot(math.ceil(burst.shape[0]/3),3,i+1)\n",
    "    plt.imshow(np.fft.fftshift(weight[i,0]),'magma')\n",
    "    plt.colorbar()\n",
    "    plt.xticks(visible = False)\n",
    "    plt.yticks(visible = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_sharpen(Input, radius, c):\n",
    "    # Input : image\n",
    "    # radius : radius of H\n",
    "    # c : images sharpening constant\n",
    "    img = Input.copy()\n",
    "    centx = int(Input.shape[0]/2)\n",
    "    centy = int(Input.shape[1]/2)\n",
    "    print(\"max max radius: \"+str(math.sqrt(centx**2+centy**2))+\" min max radius: \"+str(min(centx, centy)))\n",
    "    img = np.moveaxis(img, 2, 0) # (R, C, channel) -> (channel, R, C)\n",
    "    img_result = np.zeros(img.shape)\n",
    "#     print(img.shape)\n",
    "    for channel in range(img.shape[0]):\n",
    "        img_fft = np.fft.fft2(img[channel])\n",
    "        img_fft = np.fft.fftshift(img_fft)\n",
    "        for i in range(img_fft.shape[0]):\n",
    "            for j in range(img_fft.shape[1]):\n",
    "                cur_rad = (i-centx)**2+(j-centy)**2\n",
    "                scale = math.exp(-cur_rad / (2*(radius**2)) )\n",
    "                img_fft[i,j] = scale * img_fft[i,j]\n",
    "        img_result[channel] = np.real(np.fft.ifft2(np.fft.ifftshift(img_fft)))\n",
    "    img_result = np.moveaxis(img_result, 0, 2)\n",
    "#     print(img_result.shape)\n",
    "    img_result = np.where(img_result < 0, 0, img_result)\n",
    "    img_result = np.where(img_result > 255, 255, img_result).astype(np.uint8)\n",
    "    # image sharpening\n",
    "    img_result = (c/(2*c-1))*Input - ((1-c)/(2*c-1))*img_result\n",
    "    return img_result.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### attempt to do some post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def unsharp_masking(img, c=3/5):\n",
    "    # img_median = cv2.medianBlur(img, 1)\n",
    "    # img_lap = cv2.Laplacian(img, cv2.CV_64F)\n",
    "    # img_sharp = img_median - 0.7*img_lap\n",
    "    blur_img = cv2.GaussianBlur(img, (5,5), 0)\n",
    "    img_result = c/(2*c-1)*img - (1-c)/(2*c-1)*blur_img\n",
    "    img_result = np.where(img_result < 0, 0, img_result)\n",
    "    img_result = np.where(img_result > 255, 255, img_result).astype(np.uint8)\n",
    "    return img_result\n",
    "\n",
    "# do unsharp masking in spatial domain\n",
    "img_unsharp_masking = unsharp_masking(image_restored, 5/6)\n",
    "cv2.imwrite('result_post_unsharp_masking.png', img_unsharp_masking)\n",
    "\n",
    "# do non-local means\n",
    "img_non_local_means = cv2.fastNlMeansDenoisingColored(image_restored, None, 5, 5, 7, 21)\n",
    "cv2.imwrite('result_post_non_local_denoising.png', img_non_local_means)\n",
    "\n",
    "# higt-pass filter with different filter\n",
    "kernel = np.array([[0, -1, 0],\n",
    "                   [-1, 5,-1],\n",
    "                   [0, -1, 0]]) \n",
    "img_high_pass = cv2.filter2D(image_restored, -1, kernel)             \n",
    "cv2.imwrite('result_post_high_pass.png', img_high_pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# input: img_restored\n",
    "# output: img_restored\n",
    "plt.figure(figsize=(100,80))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(cv2.cvtColor(image_restored, cv2.COLOR_BGR2RGB))\n",
    "# post processing (image sharpening)\n",
    "# image_sharpen = gaussian_sharpen(image_restored, 500, 0.7)\n",
    "kernel = np.array([[-1, -1, -1],\n",
    "                   [-1, 9,-1],\n",
    "                   [-1, -1, -1]])\n",
    "image_sharpen = cv2.filter2D(src=image_restored, ddepth=-1, kernel=kernel)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(cv2.cvtColor(image_sharpen, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite('result.png', image_restored)\n",
    "cv2.imwrite('result_sharpen.png', image_sharpen)\n",
    "cv2.imwrite('result2.png', b)\n",
    "plt.figure(figsize=(100,80))\n",
    "plt.subplot(3,1,1)\n",
    "plt.imshow(cv2.cvtColor(image_restored, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(3,1,2)\n",
    "plt.imshow(cv2.cvtColor(image_sharpen, cv2.COLOR_BGR2RGB))\n",
    "plt.subplot(3,1,3)\n",
    "plt.imshow(cv2.cvtColor(b, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fourier spectrums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum=np.fft.fftshift(np.fft.fft2(cv2.imread('../images/bookshelf/result/out_fba.jpg', 0)))\n",
    "\n",
    "t=np.abs(spectrum)\n",
    "plt.imshow(np.log10(np.abs(spectrum)),'magma')\n",
    "plt.colorbar()\n",
    "plt.xticks(visible = False)\n",
    "plt.yticks(visible = False)\n",
    "plt.title('output image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectrum=np.fft.fftshift(np.fft.fft2(cv2.cvtColor(image_restored, cv2.COLOR_BGR2GRAY)))\n",
    "\n",
    "t=np.abs(spectrum)\n",
    "plt.imshow(np.log10(np.abs(spectrum)),'magma')\n",
    "plt.colorbar()\n",
    "plt.xticks(visible = False)\n",
    "plt.yticks(visible = False)\n",
    "plt.title('output image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
